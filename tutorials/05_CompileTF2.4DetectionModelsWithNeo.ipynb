{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling TF2.4 Models with SageMaker Neo\n",
    "\n",
    "You need to run this notebook on a SageMaker Studio Instance for a complete experience!\n",
    "\n",
    "**SageMaker Studio Kernel**: Data Science\n",
    "\n",
    "TF2.4 model zoo: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "\n",
    "We're going to use an **EfficientDet model** in this example, but you can apply the same strategy used in this notebook to compile any models from the list. Depending on the model, you only need to customize the testing code in the last section.\n",
    "\n",
    "In this exercise you'll:\n",
    "   - Get a pre-trained model from the Efficientdet\n",
    "   - Prepare the model to compile it with Neo\n",
    "   - Compile the model for the target: **X86_64**\n",
    "   - Get the optimized model and run a simple local test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required for local tests\n",
    "!pip install dlr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Get the pre-trainded model and upload it to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import io\n",
    "import tarfile\n",
    "import shutil\n",
    "import sagemaker\n",
    "\n",
    "net_version=0\n",
    "assert(net_version >= 0 and net_version <= 7)\n",
    "input_shapes=[512,640,768,896,1024,1280,1280,1536]\n",
    "img_size=input_shapes[net_version]\n",
    "\n",
    "url=f\"http://download.tensorflow.org/models/object_detection/tf2/20200711/efficientdet_d{net_version}_coco17_tpu-32.tar.gz\"\n",
    "print(f\"Downloading the model: {url}\")\n",
    "\n",
    "shutil.rmtree('export')\n",
    "with urllib.request.urlopen(url) as f:\n",
    "    with tarfile.open(fileobj=io.BytesIO(f.read()), mode=\"r:gz\") as tar:        \n",
    "        tar.extractall(path='export')\n",
    "        \n",
    "print(\"Create a model package and upload it to S3\")\n",
    "sagemaker_session = sagemaker.Session()\n",
    "model_name=f'efficientdet-d{net_version}'\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as f:\n",
    "    f.add(f\"export/efficientdet_d{net_version}_coco17_tpu-32/saved_model/\", \"export/1\")\n",
    "    f.list()\n",
    "\n",
    "s3_uri = sagemaker_session.upload_data('model.tar.gz', key_prefix=f'{model_name}/model')\n",
    "\n",
    "print(f\"Done\\nS3 uri: {s3_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Compile the model with SageMaker Neo (X86_64)\n",
    "\n",
    "**ATTENTION:** It takes around 30mins to compile an EfficientDet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "arch='X86_64' # Jetson = ARM64\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sm_client = boto3.client('sagemaker')\n",
    "compilation_job_name = f'{model_name}-tf2-{int(time.time()*1000)}'\n",
    "sm_client.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        'S3Uri': s3_uri,\n",
    "        'DataInputConfig': f'{{\"input_tensor\": [1,{img_size},{img_size},3]}}',\n",
    "        'Framework': 'TENSORFLOW',\n",
    "        'FrameworkVersion': '2.4'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': f's3://{sagemaker_session.default_bucket()}/{model_name}-tf2/optimized/',\n",
    "        'TargetPlatform': { \n",
    "            'Os': 'LINUX', \n",
    "            'Arch': arch,\n",
    "            #'Accelerator': 'NVIDIA'  # comment this if you don't have an Nvidia GPU\n",
    "        },\n",
    "        # Comment or change the following line depending on your edge device\n",
    "        # Jetson Xavier: sm_72; Jetson Nano: sm_53\n",
    "        #'CompilerOptions': '{\"trt-ver\": \"7.1.3\", \"cuda-ver\": \"10.2\", \"gpu-code\": \"sm_72\"}' # Jetpack 4.4.1\n",
    "    },\n",
    "    StoppingCondition={ 'MaxRuntimeInSeconds': 18000 }\n",
    ")\n",
    "while True:\n",
    "    resp = sm_client.describe_compilation_job(CompilationJobName=compilation_job_name)    \n",
    "    if resp['CompilationJobStatus'] in ['STARTING', 'INPROGRESS']:\n",
    "        print('Running...')\n",
    "    else:\n",
    "        print(resp['CompilationJobStatus'], compilation_job_name)\n",
    "        break\n",
    "    time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Download the compiled model\n",
    "**ATTENTION:** Only for X86_64 with no GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_path = f's3://{sagemaker_session.default_bucket()}/{model_name}-tf2/optimized/model-LINUX_{arch}.tar.gz'\n",
    "!aws s3 cp $output_model_path /tmp/model.tar.gz\n",
    "!rm -rf compiled_model && mkdir compiled_model\n",
    "!tar -xzvf /tmp/model.tar.gz -C compiled_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Run the model locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download the labels and a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "image_url='https://sagemaker-examples.readthedocs.io/en/latest/_images/cat2.jpg'\n",
    "if not os.path.exists('cat.jpg'):\n",
    "    urllib.request.urlretrieve(image_url, 'cat.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the model using the runtime DLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlr\n",
    "# load the model (CPU x86_64)\n",
    "model = dlr.DLRModel('compiled_model', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and make it squared if needed\n",
    "img = cv2.cvtColor(cv2.imread('cat.jpg'), cv2.COLOR_BGR2RGB)\n",
    "h,w,c = img.shape\n",
    "if w!=h: # pad the image and make it square\n",
    "    sqr_size = max(h,w)\n",
    "    sqr_img = np.zeros((sqr_size, sqr_size, c), dtype=np.uint8)\n",
    "    sqr_img[:h, :w],img = img,sqr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image to the expected size+transform it to pytorch/imagenet format\n",
    "x = cv2.resize(img, (img_size, img_size)).astype(np.float32) / 255.0\n",
    "# normalize\n",
    "x -= [0.485, 0.456, 0.406]\n",
    "x /= [0.229, 0.224, 0.225]\n",
    "x = x.transpose(2,0,1) # HWC --> CHW\n",
    "c,h,w = x.shape\n",
    "x = x.reshape(1,c,h,w) # CHW --> NCHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.run(x)\n",
    "idx = np.argmax(y)\n",
    "print(f\"Class id: {idx}, Score: {y[0][0][idx]}, Label: {labels[idx]}\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done! :)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.large",
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
