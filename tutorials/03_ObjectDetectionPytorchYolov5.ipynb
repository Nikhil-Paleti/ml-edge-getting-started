{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Detection @Edge with SageMaker Neo + Pytorch Yolov5\n",
    "**SageMaker Studio Kernel**: Data Science\n",
    "\n",
    "In this exercise you'll:\n",
    "   - Get a pre-trained model: Yolov5\n",
    "   - Prepare the model to compile it with Neo\n",
    "   - Compile the model for the target: **X86_64**\n",
    "   - Get the optimized model and run a simple local test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install dependencies\n",
    "\n",
    "In this step, we are installing some python modules for operating with the pre-trained Object Decection Yolov5 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update -y && apt install -y libgl1\n",
    "!pip install torch==1.7.0 torchvision==0.8.0 opencv-python dlr==1.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Get a pre-trained model and export it to torchscript\n",
    "\n",
    "In this step, we are preparing the model for being compiled by using Amazon SageMaker Neo.\n",
    "\n",
    "Amazon SageMaker Neo requires the model is formatted correctly, with the `name` and the `shape` of the expected data inputs for the trained model.\n",
    "\n",
    "The format provided can be `json` or `list`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "if not os.path.isdir('yolov5'):\n",
    "    !git clone https://github.com/ultralytics/yolov5 && \\\n",
    "        cd yolov5 && git checkout v5.0 && \\\n",
    "        git apply ../../models/01_YoloV5/01_Pytorch/yolov5_inplace.patch\n",
    "\n",
    "if not os.path.exists('yolov5s.pt'):\n",
    "    urllib.request.urlretrieve('https://github.com/ultralytics/yolov5/releases/download/v5.0/yolov5s.pt', 'yolov5s.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import sys\n",
    "sys.path.insert(0, 'yolov5')\n",
    "model = torch.load('yolov5s.pt')['model'].float().cpu()\n",
    "\n",
    "## We need to replace these two activation functions to make it work with TVM.\n",
    "\n",
    "# SiLU https://arxiv.org/pdf/1606.08415.pdf ----------------------------------------------------------------------------\n",
    "class SiLU(nn.Module):  # export-friendly version of nn.SiLU()\n",
    "    @staticmethod\n",
    "    def forward(x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "class Hardswish(nn.Module):  # export-friendly version of nn.Hardswish()\n",
    "    @staticmethod\n",
    "    def forward(x):\n",
    "        # return x * F.hardsigmoid(x)  # for torchscript and CoreML\n",
    "        return x * F.hardtanh(x + 3, 0., 6.) / 6.  # for torchscript, CoreML and ONNX\n",
    "\n",
    "for k,m in model.named_modules():\n",
    "    t = type(m)\n",
    "    layer_name = f\"{t.__module__}.{t.__name__}\"    \n",
    "    if layer_name == 'models.common.Conv':  # assign export-friendly activations\n",
    "        if isinstance(m.act, nn.Hardswish):\n",
    "            m.act = Hardswish()\n",
    "        elif isinstance(m.act, nn.SiLU):\n",
    "            m.act = SiLU()\n",
    "\n",
    "img_size=640\n",
    "inp = torch.rand(1,3,img_size,img_size).float().cpu()\n",
    "model.eval()\n",
    "p = model(inp)\n",
    "\n",
    "model_trace = torch.jit.trace(model, inp, strict=False)\n",
    "\n",
    "model_trace.save('model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create a package with the model and upload to S3\n",
    "\n",
    "Amazon SageMaker Neo is expecting the model, compressed in a `tar.gz` format, stored in an Amazon S3 Bucket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "model_name='yolov5'\n",
    "\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as f:\n",
    "    f.add(\"model.pth\")\n",
    "    f.list()\n",
    "\n",
    "s3_uri = sagemaker_session.upload_data('model.tar.gz', key_prefix=f'{model_name}/model')\n",
    "print(s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Compile the model with SageMaker Neo (X86_64)\n",
    "\n",
    "Amazon SageMaker Neo is used for optimizing a ML model on the basis of the provided Target Platform information.\n",
    "\n",
    "#### Parameters:\n",
    "\n",
    "`InputConfig`: Information in `json` format related to the ML model, such as location onf the model in the Amazon S3 Bucket, Input Shape for the ML model, and Framework used. Full list of compatible Frameworks is available in the official [AWS documentation page](https://docs.aws.amazon.com/sagemaker/latest/dg/neo-supported-devices-edge-frameworks.html).\n",
    "\n",
    "`OutputConfig`: Information in `json` format related to the Target Platform for which the model should be optimized, with OS and base Arch, and storage location on Amazon S3 Bucket where the compiled model will be stored. Full list of supported devices, architecture, and systems is available in the official [AWS documentation page](https://docs.aws.amazon.com/sagemaker/latest/dg/neo-supported-devices-edge-devices.html).\n",
    "\n",
    "For this example, we are targeting as platform the instance where this notebook is executed. The information related to the instance are: `OS` -> LINUX, `Arch` -> X86_64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sm_client = boto3.client('sagemaker')\n",
    "compilation_job_name = f'{model_name}-pytorch-{int(time.time()*1000)}'\n",
    "sm_client.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        'S3Uri': s3_uri,\n",
    "        'DataInputConfig': f'{{\"input\": [1,3,{img_size},{img_size}]}}',\n",
    "        'Framework': 'PYTORCH'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': f's3://{sagemaker_session.default_bucket()}/{model_name}-pytorch/optimized/',\n",
    "        'TargetPlatform': { \n",
    "            'Os': 'LINUX', \n",
    "            'Arch': 'X86_64'\n",
    "        }\n",
    "    },\n",
    "    StoppingCondition={ 'MaxRuntimeInSeconds': 900 }\n",
    ")\n",
    "while True:\n",
    "    resp = sm_client.describe_compilation_job(CompilationJobName=compilation_job_name)    \n",
    "    if resp['CompilationJobStatus'] in ['STARTING', 'INPROGRESS']:\n",
    "        print('Running...')\n",
    "    else:\n",
    "        print(resp['CompilationJobStatus'], compilation_job_name)\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Download the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_path = f's3://{sagemaker_session.default_bucket()}/{model_name}-pytorch/optimized/model-LINUX_X86_64.tar.gz'\n",
    "!aws s3 cp $output_model_path /tmp/model.tar.gz\n",
    "!rm -rf model_object_detection && mkdir model_object_detection\n",
    "!tar -xzvf /tmp/model.tar.gz -C model_object_detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Run the model locally\n",
    "\n",
    "For testing our compiled model, we are downloading an input image to provide for the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "urllib.request.urlretrieve('https://i2.wp.com/petcaramelo.com/wp-content/uploads/2020/05/doberman-cores.jpg', 'dogs.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Classes\n",
    "labels= ['person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat', 'traffic light',\n",
    "        'fire hydrant', 'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep', 'cow',\n",
    "        'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
    "        'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard', 'surfboard',\n",
    "        'tennis racket', 'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple',\n",
    "        'sandwich', 'orange', 'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
    "        'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse', 'remote', 'keyboard', 'cell phone',\n",
    "        'microwave', 'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear',\n",
    "        'hair drier', 'toothbrush']  # class names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model using the runtime DLR\n",
    "\n",
    "Compiled model with Amazon SageMaker Neo can be managed and executed by using the DLR module.\n",
    "\n",
    "DLR is a compact, common runtime for deep learning models and decision tree models compiled by AWS SageMaker Neo, TVM, or Treelite.\n",
    "\n",
    "For more information, please visit the official [GitHub repository for DLR](https://github.com/neo-ai/neo-ai-dlr).\n",
    "\n",
    "For loading the model using the DLR library, we have to provide the following information:\n",
    "\n",
    "1. Location of the compiled model\n",
    "2. Processor type of the target platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlr\n",
    "# load the model (CPU x86_64)\n",
    "model = dlr.DLRModel('model_object_detection', 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execute Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'../models/01_YoloV5/01_Pytorch')\n",
    "from processing import Processor\n",
    "proc = Processor(labels, threshold=0.25, iou_threshold=0.45)\n",
    "img = cv2.imread('dogs.jpg')\n",
    "x = proc.pre_process(img)\n",
    "y = model.run(x)[0]\n",
    "(bboxes, scores, cids), image = proc.post_process(y, img.shape, img.copy())\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done! :)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
