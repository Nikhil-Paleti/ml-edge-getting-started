{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification @Edge with SageMaker Neo + Pytorch + Resnet18\n",
    "**SageMaker Studio Kernel**: Data Science\n",
    "\n",
    "In this exercise you'll:\n",
    "   - Get a pre-trained model from the torchvision model zoo: Resnet18\n",
    "   - Prepare the model to compile it with Neo\n",
    "   - Compile the model for the target: **X86_64**\n",
    "   - Get the optimized model and run a simple local test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!apt update -y && apt install -y libgl1\n",
    "!pip install torch==1.7.0 torchvision==0.8.0 opencv-python dlr==1.8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Load a pre-trained model from the model zoo and trace it with Pytorch JIT\n",
    "-> SagMaker Neo expectes the model in the traced format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "img_size = 224\n",
    "resnet18 = models.resnet18(pretrained=True)\n",
    "input_shape = [1, 3, img_size, img_size]\n",
    "trace = torch.jit.trace(resnet18.float().eval(), torch.zeros(input_shape).float())\n",
    "trace.save(\"model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Create a package with the model and upload to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tarfile\n",
    "import sagemaker\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "model_name='resnet18'\n",
    "\n",
    "with tarfile.open(\"model.tar.gz\", \"w:gz\") as f:\n",
    "    f.add(\"model.pth\")\n",
    "    f.list()\n",
    "\n",
    "s3_uri = sagemaker_session.upload_data('model.tar.gz', key_prefix=f'{model_name}/model')\n",
    "print(s3_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Compile the model with SageMaker Neo (X86_64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import boto3\n",
    "import sagemaker\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "sm_client = boto3.client('sagemaker')\n",
    "compilation_job_name = f'{model_name}-pytorch-{int(time.time()*1000)}'\n",
    "sm_client.create_compilation_job(\n",
    "    CompilationJobName=compilation_job_name,\n",
    "    RoleArn=role,\n",
    "    InputConfig={\n",
    "        'S3Uri': s3_uri,\n",
    "        'DataInputConfig': f'{{\"input\": [1,3,{img_size},{img_size}]}}',\n",
    "        'Framework': 'PYTORCH'\n",
    "    },\n",
    "    OutputConfig={\n",
    "        'S3OutputLocation': f's3://{sagemaker_session.default_bucket()}/{model_name}-pytorch/optimized/',\n",
    "        'TargetPlatform': { \n",
    "            'Os': 'LINUX', \n",
    "            'Arch': 'X86_64',\n",
    "        },\n",
    "    },\n",
    "    StoppingCondition={ 'MaxRuntimeInSeconds': 900 }\n",
    ")\n",
    "while True:\n",
    "    resp = sm_client.describe_compilation_job(CompilationJobName=compilation_job_name)    \n",
    "    if resp['CompilationJobStatus'] in ['STARTING', 'INPROGRESS']:\n",
    "        print('Running...')\n",
    "    else:\n",
    "        print(resp['CompilationJobStatus'], compilation_job_name)\n",
    "        break\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Download the compiled model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model_path = f's3://{sagemaker_session.default_bucket()}/{model_name}-pytorch/optimized/model-LINUX_X86_64.tar.gz'\n",
    "!aws s3 cp $output_model_path /tmp/model.tar.gz\n",
    "!rm -rf model_classifier && mkdir model_classifier\n",
    "!tar -xzvf /tmp/model.tar.gz -C model_classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Run the model locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### download the labels and a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "labels_url='https://raw.githubusercontent.com/DenWhiteHouse/DogClassification/master/imagenet1000_clsidx_to_labels.txt'\n",
    "image_url='https://sagemaker-examples.readthedocs.io/en/latest/_images/cat2.jpg'\n",
    "if not os.path.exists('cat.jpg'):\n",
    "    urllib.request.urlretrieve(labels_url, 'labels.txt')\n",
    "    urllib.request.urlretrieve(image_url, 'cat.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# quick and dirty parser for the labels\n",
    "labels = {}\n",
    "for l in open('labels.txt', 'r').read().splitlines():\n",
    "    l = l.strip().replace('{', '').replace('}', '')\n",
    "    l = l[:-1] if l.endswith(',') else l\n",
    "    cls_id,label = [t.strip() for t in l.split(':')]\n",
    "    labels[int(cls_id)] = label[1:-1] # remove the single quotes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load the model using the runtime DLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlr\n",
    "# load the model (CPU x86_64)\n",
    "model = dlr.DLRModel('model_classifier', 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the image and make it squared if needed\n",
    "img = cv2.cvtColor(cv2.imread('cat.jpg'), cv2.COLOR_BGR2RGB)\n",
    "h,w,c = img.shape\n",
    "if w!=h: # pad the image and make it square\n",
    "    sqr_size = max(h,w)\n",
    "    sqr_img = np.zeros((sqr_size, sqr_size, c), dtype=np.uint8)\n",
    "    sqr_img[:h, :w],img = img,sqr_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resize the image to the expected size+transform it to pytorch/imagenet format\n",
    "x = cv2.resize(img, (img_size, img_size)).astype(np.float32) / 255.0\n",
    "# normalize\n",
    "x -= [0.485, 0.456, 0.406]\n",
    "x /= [0.229, 0.224, 0.225]\n",
    "x = x.transpose(2,0,1) # HWC --> CHW\n",
    "c,h,w = x.shape\n",
    "x = x.reshape(1,c,h,w) # CHW --> NCHW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model.run(x)\n",
    "idx = np.argmax(y)\n",
    "print(f\"Class id: {idx}, Score: {y[0][0][idx]}, Label: {labels[idx]}\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done! :)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
